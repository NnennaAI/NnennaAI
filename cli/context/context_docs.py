# cli/context/context_docs.py
from rich.console import Console
from rich.markdown import Markdown

console = Console()

def show_init_output():
    console.print("\nâœ… [bold green]Project initialized using the 'starter-rag' template[/bold green]")
    console.print("ğŸ“ Created directory: [bold]./my-rag-pipeline/[/bold]")
    console.print("ğŸ“„ Generated files: config.yaml, .env.example, run_rag_pipeline.py")
    console.print("\nğŸ§ª Evaluation engine: Ragas (faithfulness, relevance)")
    console.print("ğŸ” Security: PII redaction enabled (spaCy-based)")
    console.print("\nâ–¶ï¸ [bold]Next:[/bold] run your pipeline with:")
    console.print("    cd my-rag-pipeline && nai run --query \"What is NnennaAI?\"")
    console.print("\nğŸ’¡ Tip: Customize your pipeline via config.yaml")
    console.print("ğŸ“š Learn more: https://nnenn.ai/docs/templates/starter-rag\n")

def show_run_output():
    console.print("\nğŸ“¥ Loading config: config.yaml")
    console.print("ğŸ”— Using vector DB: Qdrant | Embeddings: text-embedding-3-small")
    console.print("ğŸ“š Retrieved 5 relevant chunks (top-k=5)")
    console.print("ğŸ¤– Generating response using GPT-4...\n")
    console.print("âœ… [bold green]Done![/bold green] Output saved to: outputs/response.json")
    console.print("\nğŸ“„ Response (truncated):")
    console.print("    \"The API security doc emphasizes...\"")
    console.print("\nâ–¶ï¸ [bold]Next:[/bold] Assess this output:")
    console.print("    nai assess outputs/response.json")
    console.print("\nğŸ’¡ Tip: Add --verbose to see token usage and costs\n")

def show_assess_output():
    console.print("\nğŸ“ˆ Running assessment using Ragas...")
    console.print("âœ… [bold green]Assessment complete![/bold green]\n")
    console.print("ğŸ“Š Ragas Score: 0.82")
    console.print("   - Faithfulness: 92%")
    console.print("   - Completeness: 71%")
    console.print("   - Context Precision: 88%\n")
    console.print("ğŸ“„ Assessment report saved to: eval/assessment.md")
    console.print("\nğŸ’¡ Tip: Improve your retriever config to boost completeness")
    console.print("ğŸ”— Learn more about evaluation: https://nnenn.ai/docs/eval\n")

def show_scan_output():
    console.print("\nğŸ” Scanning 12 files for PII (emails, names, IDs, etc)...")
    console.print("âœ… [bold green]Scan complete[/bold green]\n")
    console.print("ğŸ” PII Found: 4 matches in 3 files")
    console.print("âœ‚ï¸ Redacted outputs saved to: ./cleaned/")
    console.print("ğŸ“„ Redaction log: scan/report.json\n")
    console.print("ğŸ’¡ Tip: Add --report markdown to generate an audit summary")
    console.print("ğŸ“š Secure-by-default: https://nnenn.ai/docs/security\n")

def show_report_output():
    console.print("\nğŸ“Š Report Summary: Evaluation Trends\n")
    console.print("ğŸ§ª Most Recent Run:")
    console.print("   - Score: 0.82 | Faithfulness: 92% | Completeness: 71%")
    console.print("\nğŸ“ˆ Change vs Previous:")
    console.print("   - Completeness improved (+12%)")
    console.print("   - Context precision stable\n")
    console.print("ğŸ“„ Full report saved to: eval/trends.md\n")
    console.print("ğŸ’¡ Tip: Include eval history in team reviews for model performance")
    console.print("ğŸ“š Docs: https://nnenn.ai/docs/reporting\n")
