# cli/commands/assess.py
import typer
from context.context_docs import show_assess_output

app = typer.Typer(help="ğŸ§ª Assess the quality of GenAI output")

@app.command()
def file(
    filepath: str = typer.Argument(..., help="Path to the output JSON file to assess"),
    metrics: list[str] = typer.Option(["faithfulness", "completeness"], help="Metrics to use for assessment"),
    engine: str = typer.Option("ragas", help="Evaluation engine (ragas or galileo)")
):
    """
    Assess the output of a GenAI pipeline.
    """
    typer.echo(f"ğŸ“‚ Loading file: {filepath}")
    typer.echo(f"ğŸ“Š Metrics: {', '.join(metrics)}")
    typer.echo(f"âš™ï¸ Engine: {engine}")

    # Simulated assessment logic
    typer.echo("â³ Running assessment...\n")

    # Show contextual output
    show_assess_output()